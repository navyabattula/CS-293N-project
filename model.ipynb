{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.merge import concatenate\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(\"bytes1.pickle\",'rb')\n",
    "train_bytes = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile1 = open(\"bytes2.pickle\",'rb')\n",
    "test_bytes = pickle.load(infile1)\n",
    "infile1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile2 = open(\"statistics1.pickle\",'rb')\n",
    "X_train = pickle.load(infile2)\n",
    "infile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile3 = open(\"statistics2.pickle\",'rb')\n",
    "X_test = pickle.load(infile3)\n",
    "infile3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile4 = open(\"timeseries1.pickle\",'rb')\n",
    "new_dict1 = pickle.load(infile4)\n",
    "infile4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile5 = open(\"timeseries2.pickle\",'rb')\n",
    "new_dict2 = pickle.load(infile5)\n",
    "infile5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile6 = open(\"labels1.pickle\",'rb')\n",
    "train_labels = pickle.load(infile6)\n",
    "infile6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile7 = open(\"labels2.pickle\",'rb')\n",
    "test_labels = pickle.load(infile7)\n",
    "infile7.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = a_layer = Input(shape=(76, ) , name=\"a\")\n",
    "hidden1 = Dense(200, activation=\"relu\")(visible)\n",
    "output1 = Dense(200, activation=\"relu\")(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_l = b_layer = Input(shape=(1024, 3) , name=\"b\")\n",
    "hidden1_l = Dense(512, activation=\"relu\", name=\"m1\")(visible_l)\n",
    "hidden2_l = LSTM(256, return_sequences=True)(hidden1_l)\n",
    "hidden3_l = LSTM(256, return_sequences=True)(hidden2_l)\n",
    "hidden4_l = LSTM(256)(hidden3_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = c_layer = Input(shape=(1800, 1), name=\"c\")\n",
    "conv1 = Conv1D(256, kernel_size=2, activation='relu')(visible)\n",
    "conv2 = Conv1D(256, kernel_size=2, activation='relu')(conv1)\n",
    "pool1 = MaxPooling1D(pool_size=(2,))(conv2)\n",
    "conv3 = Conv1D(128, kernel_size=2, activation='relu')(pool1)\n",
    "conv4 = Conv1D(128, kernel_size=2, activation='relu')(conv3)\n",
    "pool2 = MaxPooling1D(pool_size=(2,))(conv4)\n",
    "output2 = Flatten()(pool2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = concatenate([output1, hidden4_l, output2])\n",
    "hiddeno_1=Dense(128, activation='relu')(merge)\n",
    "hiddeno_2=Dense(128, activation='relu')(hiddeno_1)\n",
    "output_final = Dense(8, activation='softmax')(hiddeno_2)\n",
    "model = Model(inputs=[a_layer, b_layer, c_layer], outputs=output_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x={\"a\": X_train, \"b\": new_dict1, \"c\": train_bytes}, y=train_labels, epochs=40, callbacks=[callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x={\"a\": X_test, \"b\": new_dict2, \"c\": test_bytes}, y=test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
